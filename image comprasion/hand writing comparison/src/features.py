import cv2
import numpy as np
from skimage.feature import hog, local_binary_pattern
from skimage.morphology import skeletonize
from skimage.transform import rotate
from skimage.filters import threshold_local
from skimage.measure import find_contours

def _adaptive_binarize(img):
    T = threshold_local(img, block_size=35, offset=10)
    bin_img = (img > T).astype(np.uint8) * 255
    return bin_img

def _deskew(gray):
    # Edge + Hough line angle estimate
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLines(edges, 1, np.pi/180, 120)
    angle = 0.0
    if lines is not None and len(lines) > 0:
        # Use median angle of detected lines around horizontal
        angs = []
        for rho, theta in lines[:,0,:]:
            a = (theta - np.pi/2)  # around 0 if near horizontal text lines
            angs.append(a)
        angle = np.median(angs) * 180/np.pi
        angle = np.clip(angle, -10, 10)  # keep reasonable
    # rotate using skimage to avoid cropping
    rotated = rotate(gray, angle, resize=False, mode='edge', preserve_range=True).astype(np.uint8)
    return rotated, angle

def preprocess(image_bgr, target=256):
    if image_bgr.ndim == 3:
        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    else:
        gray = image_bgr.copy()

    gray = cv2.medianBlur(gray, 3)
    deskewed, angle = _deskew(gray)
    bin_img = _adaptive_binarize(deskewed)

    # center-pad to square, then resize
    h, w = bin_img.shape
    side = max(h, w)
    pad_top = (side - h) // 2
    pad_bottom = side - h - pad_top
    pad_left = (side - w) // 2
    pad_right = side - w - pad_left
    padded = cv2.copyMakeBorder(bin_img, pad_top, pad_bottom, pad_left, pad_right,
                                cv2.BORDER_CONSTANT, value=0)
    resized = cv2.resize(padded, (target, target), interpolation=cv2.INTER_AREA)
    return resized, {'deskew_angle': angle, 'padded_shape': padded.shape}

def _lbp_hist(img, P=8, R=1):
    lbp = local_binary_pattern(img, P=P, R=R, method='uniform')
    (hist, _) = np.histogram(lbp.ravel(),
                             bins=np.arange(0, P + 3),
                             range=(0, P + 2),
                             density=True)
    return hist

def _ink_ratio(img):
    # assuming white background 0, ink=255 after binarization invert if necessary
    ink = (img > 0).sum()
    return ink / img.size

def _edge_density(img):
    edges = cv2.Canny(img, 50, 150)
    return edges.sum() / 255.0 / img.size

def _contour_complexity(img):
    contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return 0.0
    perims = [cv2.arcLength(c, True) for c in contours]
    areas = [cv2.contourArea(c) for c in contours if cv2.contourArea(c) > 0]
    if not areas:
        return 0.0
    return (np.mean(perims) / (np.mean(areas) ** 0.5))

def extract_features(bin_img):
    # HOG
    hog_vec = hog(bin_img, pixels_per_cell=(16,16), cells_per_block=(2,2),
                  feature_vector=True, orientations=9, block_norm='L2-Hys')

    # LBP
    lbp_vec = _lbp_hist(bin_img, P=8, R=1)

    # Simple stats
    stats = np.array([
        _ink_ratio(bin_img),
        _edge_density(bin_img),
        _contour_complexity(bin_img),
    ], dtype=np.float32)

    # concatenate
    feat = np.concatenate([hog_vec, lbp_vec, stats], axis=0).astype(np.float32)
    # normalize
    norm = np.linalg.norm(feat) + 1e-8
    feat = feat / norm
    return feat

def preprocess_and_featurize(image_bgr):
    proc, meta = preprocess(image_bgr)
    feat = extract_features(proc)
    return proc, feat, meta
